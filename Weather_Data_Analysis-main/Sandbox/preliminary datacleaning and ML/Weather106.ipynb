{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6056c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6187536",
   "metadata": {},
   "source": [
    "This notebook is preliminary ETL for data from the weather API. <br>\n",
    "We work with data for Union Square in San Francisco; (37.7879, -122.4079) for API.  <br>\n",
    "<b> Beware, returned data says has coordinates (38, -122.75) which is 30 miles north in Point Reyes! </b> <br>\n",
    "We pulled data from 2000-01-01 to 2020-12-31. <br>\n",
    "We took temperature, humidity, rainfal, snowfal, cloudcover, windspeed, and wind-direction hourly. <br>\n",
    "<hr> \n",
    "We will also take max temp, min temp, rain, snow, and percip-hours daily. <br>\n",
    "These will need separate and different dataframe processing. <br>\n",
    "We are taking in data via downloaded csv, and we need separate daily/hourly csv files because different column headers, numbers of columns.<br>\n",
    "<hr>\n",
    "We chose ISO format for date/time; and USian (not-metric) units for the rest.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b1148",
   "metadata": {},
   "source": [
    "This run is with \"GMT +0\" time zone; in the future, we will need to specify the timezone appropriate to the location.<br>\n",
    "API allows \"GMT +0\" time zone for hourly data, but not for daily data - says \"error, time zone must be specified\" -- except does time zone even matter for dailies? I think not for us, except for reproducibility.<br>\n",
    "If we're stuck with something other than \"GMT +0\", we could get strange behaviour whenif daylight savings time kicks in; can check for that by requesting sunrise time data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba484a",
   "metadata": {},
   "source": [
    "## Hourly data: load, clean, pivot for joining with daily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beff8b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">temperature_2m_degF</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">winddirection_10m_deg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pure_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>51.6</td>\n",
       "      <td>51.3</td>\n",
       "      <td>51.4</td>\n",
       "      <td>48.1</td>\n",
       "      <td>47.8</td>\n",
       "      <td>47.8</td>\n",
       "      <td>46.7</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>52.2</td>\n",
       "      <td>51.8</td>\n",
       "      <td>51.2</td>\n",
       "      <td>47.8</td>\n",
       "      <td>47.8</td>\n",
       "      <td>47.6</td>\n",
       "      <td>47.5</td>\n",
       "      <td>47.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>45.4</td>\n",
       "      <td>...</td>\n",
       "      <td>326.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>52.2</td>\n",
       "      <td>52.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>48.1</td>\n",
       "      <td>48.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.9</td>\n",
       "      <td>47.9</td>\n",
       "      <td>47.7</td>\n",
       "      <td>46.9</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>52.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.9</td>\n",
       "      <td>47.6</td>\n",
       "      <td>47.9</td>\n",
       "      <td>49.4</td>\n",
       "      <td>49.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>45.9</td>\n",
       "      <td>...</td>\n",
       "      <td>280.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>53.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>49.8</td>\n",
       "      <td>49.2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.7</td>\n",
       "      <td>49.2</td>\n",
       "      <td>...</td>\n",
       "      <td>342.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           temperature_2m_degF                                            \\\n",
       "hour                        0     1     2     3     4     5     6     7    \n",
       "pure_date                                                                  \n",
       "2000-01-01                51.6  51.3  51.4  48.1  47.8  47.8  46.7  45.6   \n",
       "2000-01-02                52.2  51.8  51.2  47.8  47.8  47.6  47.5  47.2   \n",
       "2000-01-03                52.2  52.1  51.8  48.1  48.3  48.0  47.9  47.9   \n",
       "2000-01-04                52.9  52.0  50.9  47.6  47.9  49.4  49.2  47.3   \n",
       "2000-01-05                53.0  53.2  53.2  49.8  49.2  49.4  50.0  50.0   \n",
       "\n",
       "                        ... winddirection_10m_deg                              \\\n",
       "hour          8     9   ...                    14     15     16     17     18   \n",
       "pure_date               ...                                                     \n",
       "2000-01-01  45.0  43.1  ...                   3.0    7.0  350.0  333.0  315.0   \n",
       "2000-01-02  46.8  45.4  ...                 326.0  327.0  329.0  327.0  323.0   \n",
       "2000-01-03  47.7  46.9  ...                 352.0    8.0   27.0   29.0  339.0   \n",
       "2000-01-04  47.3  45.9  ...                 280.0  277.0  291.0  261.0  180.0   \n",
       "2000-01-05  49.7  49.2  ...                 342.0  343.0  335.0  324.0  318.0   \n",
       "\n",
       "                                               \n",
       "hour           19     20     21     22     23  \n",
       "pure_date                                      \n",
       "2000-01-01  306.0  307.0  308.0  296.0  297.0  \n",
       "2000-01-02  317.0  309.0  306.0  303.0  302.0  \n",
       "2000-01-03  315.0  252.0  267.0  275.0  283.0  \n",
       "2000-01-04  162.0  151.0  161.0  188.0  195.0  \n",
       "2000-01-05  318.0  319.0  323.0  314.0  310.0  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "# rename columns because provided column headers contain non-ascii characters\n",
    "file_path =\"hourly.csv\"\n",
    "hourly_columns = ['time',\n",
    "           'temperature_2m_degF', \n",
    "           'relativehumidity_2m_perc', \n",
    "           'rain_inch',\n",
    "           'snowfall_cm', \n",
    "           'cloudcover_perc', \n",
    "           'windspeed_10m_mph',\n",
    "           'winddirection_10m_deg']\n",
    "\n",
    "raw_hrly_df1 = pd.read_csv(file_path, skiprows=4, names=hourly_columns)\n",
    "\n",
    "# When wind speed is 0, wind direction is NaN. Otherwise, wind directions varies from 1 to 360.\n",
    "# We replace NaNs with 0s to avoid errors; and losing no data as 0 never appears in the original.\n",
    "raw_hrly_df1[\"winddirection_10m_deg\"].fillna(0, inplace=True)\n",
    "\n",
    "# We convert the provided ISO string 'time' into\n",
    "#    a 'pure_date' in python datetime format for merging with daily data; and\n",
    "#    an 'hour' integer, for pivoting.\n",
    "\n",
    "raw_hrly_df1[\"pure_date\"] = raw_hrly_df1['time'].map(lambda x: \n",
    "                                                     datetime.datetime.fromisoformat(x[0:10]))\n",
    "raw_hrly_df1[\"hour\"] = raw_hrly_df1['time'].map(lambda x: datetime.datetime.fromisoformat(x).hour)\n",
    "\n",
    "# Now we pivot the dataframe on the \"hour\" variable: for each value of 'pure_date',\n",
    "#  - The raw dataframe has 24 rows (one for each hour) with: 7 weather columns; and\n",
    "#   3 date/time columns: original string 'time', datetime 'pure_date', integer 'hour; and\n",
    "#    mostly meaningless sequential index.\n",
    "#   The clean dataframe has 1 row with: index 'pure_date'; and 7*24=168 weather-at-hour columns. \n",
    "\n",
    "clean_hrly_df1 = raw_hrly_df1.pivot(index = 'pure_date',\n",
    "                                    columns = 'hour', values = hourly_columns[1:])\n",
    "clean_hrly_df1.head()\n",
    "\n",
    "# The two percentage columns that used to be int64 got converted to float64 during pivoting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3656e",
   "metadata": {},
   "source": [
    "### Load daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cbe3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_degF_max</th>\n",
       "      <th>temperature_2m_degF_min</th>\n",
       "      <th>rain_inch</th>\n",
       "      <th>snowfall_cm</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.2</td>\n",
       "      <td>43.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.9</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.2</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.8</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_2m_degF_max  temperature_2m_degF_min  rain_inch  snowfall_cm  \\\n",
       "0                     52.2                     43.1       0.00          0.0   \n",
       "1                     52.3                     45.1       0.00          0.0   \n",
       "2                     52.9                     42.8       0.00          0.0   \n",
       "3                     53.2                     44.2       0.02          0.0   \n",
       "4                     56.8                     45.8       0.00          0.0   \n",
       "\n",
       "   precipitation_hours       date  \n",
       "0                  0.0 2000-01-01  \n",
       "1                  0.0 2000-01-02  \n",
       "2                  0.0 2000-01-03  \n",
       "3                  2.0 2000-01-04  \n",
       "4                  0.0 2000-01-05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "# rename columns because provided column headers contain non-ascii characters\n",
    "file_path =\"daily.csv\"\n",
    "daily_columns = ['time',\n",
    "           'temperature_2m_degF_max',\n",
    "           'temperature_2m_degF_min',  \n",
    "           'rain_inch',\n",
    "           'snowfall_cm',\n",
    "           'precipitation_hours'\n",
    "          ]\n",
    "\n",
    "raw_daily_df1 = pd.read_csv(file_path, skiprows=4, names=daily_columns)\n",
    "\n",
    "# convert ISO date into datetime\n",
    "raw_daily_df1[\"date\"] = raw_daily_df1['time'].map(lambda x: datetime.datetime.fromisoformat(x))\n",
    "raw_daily_df1.drop('time', axis=1, inplace=True)\n",
    "\n",
    "raw_daily_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb459e4d",
   "metadata": {},
   "source": [
    "### Join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a82d6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_degF_max</th>\n",
       "      <th>temperature_2m_degF_min</th>\n",
       "      <th>rain_inch</th>\n",
       "      <th>snowfall_cm</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>date</th>\n",
       "      <th>(temperature_2m_degF, 0)</th>\n",
       "      <th>(temperature_2m_degF, 1)</th>\n",
       "      <th>(temperature_2m_degF, 2)</th>\n",
       "      <th>(temperature_2m_degF, 3)</th>\n",
       "      <th>...</th>\n",
       "      <th>(winddirection_10m_deg, 14)</th>\n",
       "      <th>(winddirection_10m_deg, 15)</th>\n",
       "      <th>(winddirection_10m_deg, 16)</th>\n",
       "      <th>(winddirection_10m_deg, 17)</th>\n",
       "      <th>(winddirection_10m_deg, 18)</th>\n",
       "      <th>(winddirection_10m_deg, 19)</th>\n",
       "      <th>(winddirection_10m_deg, 20)</th>\n",
       "      <th>(winddirection_10m_deg, 21)</th>\n",
       "      <th>(winddirection_10m_deg, 22)</th>\n",
       "      <th>(winddirection_10m_deg, 23)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.2</td>\n",
       "      <td>43.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>51.6</td>\n",
       "      <td>51.3</td>\n",
       "      <td>51.4</td>\n",
       "      <td>48.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>52.2</td>\n",
       "      <td>51.8</td>\n",
       "      <td>51.2</td>\n",
       "      <td>47.8</td>\n",
       "      <td>...</td>\n",
       "      <td>326.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.9</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>52.2</td>\n",
       "      <td>52.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>48.1</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.2</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>52.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.9</td>\n",
       "      <td>47.6</td>\n",
       "      <td>...</td>\n",
       "      <td>280.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.8</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>49.8</td>\n",
       "      <td>...</td>\n",
       "      <td>342.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_2m_degF_max  temperature_2m_degF_min  rain_inch  snowfall_cm  \\\n",
       "0                     52.2                     43.1       0.00          0.0   \n",
       "1                     52.3                     45.1       0.00          0.0   \n",
       "2                     52.9                     42.8       0.00          0.0   \n",
       "3                     53.2                     44.2       0.02          0.0   \n",
       "4                     56.8                     45.8       0.00          0.0   \n",
       "\n",
       "   precipitation_hours       date  (temperature_2m_degF, 0)  \\\n",
       "0                  0.0 2000-01-01                      51.6   \n",
       "1                  0.0 2000-01-02                      52.2   \n",
       "2                  0.0 2000-01-03                      52.2   \n",
       "3                  2.0 2000-01-04                      52.9   \n",
       "4                  0.0 2000-01-05                      53.0   \n",
       "\n",
       "   (temperature_2m_degF, 1)  (temperature_2m_degF, 2)  \\\n",
       "0                      51.3                      51.4   \n",
       "1                      51.8                      51.2   \n",
       "2                      52.1                      51.8   \n",
       "3                      52.0                      50.9   \n",
       "4                      53.2                      53.2   \n",
       "\n",
       "   (temperature_2m_degF, 3)  ...  (winddirection_10m_deg, 14)  \\\n",
       "0                      48.1  ...                          3.0   \n",
       "1                      47.8  ...                        326.0   \n",
       "2                      48.1  ...                        352.0   \n",
       "3                      47.6  ...                        280.0   \n",
       "4                      49.8  ...                        342.0   \n",
       "\n",
       "   (winddirection_10m_deg, 15)  (winddirection_10m_deg, 16)  \\\n",
       "0                          7.0                        350.0   \n",
       "1                        327.0                        329.0   \n",
       "2                          8.0                         27.0   \n",
       "3                        277.0                        291.0   \n",
       "4                        343.0                        335.0   \n",
       "\n",
       "   (winddirection_10m_deg, 17)  (winddirection_10m_deg, 18)  \\\n",
       "0                        333.0                        315.0   \n",
       "1                        327.0                        323.0   \n",
       "2                         29.0                        339.0   \n",
       "3                        261.0                        180.0   \n",
       "4                        324.0                        318.0   \n",
       "\n",
       "   (winddirection_10m_deg, 19)  (winddirection_10m_deg, 20)  \\\n",
       "0                        306.0                        307.0   \n",
       "1                        317.0                        309.0   \n",
       "2                        315.0                        252.0   \n",
       "3                        162.0                        151.0   \n",
       "4                        318.0                        319.0   \n",
       "\n",
       "   (winddirection_10m_deg, 21)  (winddirection_10m_deg, 22)  \\\n",
       "0                        308.0                        296.0   \n",
       "1                        306.0                        303.0   \n",
       "2                        267.0                        275.0   \n",
       "3                        161.0                        188.0   \n",
       "4                        323.0                        314.0   \n",
       "\n",
       "   (winddirection_10m_deg, 23)  \n",
       "0                        297.0  \n",
       "1                        302.0  \n",
       "2                        283.0  \n",
       "3                        195.0  \n",
       "4                        310.0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warning says, flatten column names or else join will throw errors in future versions\n",
    "clean_hrly_df1.columns = clean_hrly_df1.columns.to_flat_index()\n",
    "awesome_df = raw_daily_df1.join(clean_hrly_df1, on = 'date' )\n",
    "awesome_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c7726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date into numbers: year, month, and day-of-the-year.\n",
    "# The 'month' field is for the month-label machine learning. \n",
    "# The day_of_year field is for the season-clusters machine learning. \n",
    "# The 'year' field is for maybe pivoting on, for the season-clusters machine learning. \n",
    "# The day_of_year field runs from 1 to 365 (366 for leap years): February 3rd would be 34. \n",
    "# We keep the whole date formatted as datetime for time intervals like 2011-12-28 to 2012-01-17.\n",
    "\n",
    "awesome_df['year'] = awesome_df[\"date\"].map(lambda x: x.year)\n",
    "awesome_df['month'] = awesome_df[\"date\"].map(lambda x: x.month)\n",
    "\n",
    "# the next tw lines of code are stolen from\n",
    "# https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-11.php\n",
    "# which says nothing about licenses\n",
    "def day_of_year(x):\n",
    "    return (x - datetime.datetime(x.year, 1, 1)).days + 1\n",
    "\n",
    "awesome_df['day_of_year'] = awesome_df[\"date\"].map(lambda x: day_of_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1620a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result for other people's use \n",
    "awesome_df.to_csv('awesome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c5c3b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads in data from the first two filename inputs,\n",
    "# performs ETL, and writes the result to the third filename input\n",
    "# NO ERROR HANDLING\n",
    "\n",
    "def etl_step1(hourly_input_file, daily_input_file, output_file):\n",
    "    # Load the hourly dataset.\n",
    "    # rename columns because provided column headers contain non-ascii characters\n",
    "    hourly_columns = ['time', 'temperature_2m_degF', 'relativehumidity_2m_perc',\n",
    "                      'rain_inch', 'snowfall_cm', 'cloudcover_perc',\n",
    "                      'windspeed_10m_mph', 'winddirection_10m_deg']\n",
    "    raw_hrly_df1 = pd.read_csv(hourly_input_file, skiprows=4, names=hourly_columns)\n",
    "\n",
    "    # When wind speed is 0, wind direction is NaN. Otherwise, wind directions varies from 1 to 360.\n",
    "    # We replace NaNs with 0s to avoid errors; and losing no data as 0 never appears in the original.\n",
    "    raw_hrly_df1[\"winddirection_10m_deg\"].fillna(0, inplace=True)\n",
    "\n",
    "    # We convert the provided ISO string 'time' into\n",
    "    #    a 'pure_date' in python datetime format for merging with daily data; and\n",
    "    #    an 'hour' integer, for pivoting.\n",
    "    raw_hrly_df1[\"pure_date\"] = raw_hrly_df1['time'].map(lambda x: \n",
    "                                                     datetime.datetime.fromisoformat(x[0:10]))\n",
    "    raw_hrly_df1[\"hour\"] = raw_hrly_df1['time'].map(lambda x: datetime.datetime.fromisoformat(x).hour)\n",
    "\n",
    "    # Now we pivot the dataframe on the \"hour\" variable: for each value of 'pure_date',\n",
    "    #  - The raw dataframe has 24 rows (one for each hour) with: 7 weather columns; and\n",
    "    #   3 date/time columns: original string 'time', datetime 'pure_date', integer 'hour; and\n",
    "    #    mostly meaningless sequential index.\n",
    "    #   The clean dataframe has 1 row with: index 'pure_date'; and 7*24=168 weather-at-hour columns. \n",
    "    clean_hrly_df1 = raw_hrly_df1.pivot(index = 'pure_date',\n",
    "                                    columns = 'hour', values = hourly_columns[1:])\n",
    "    # The two percentage columns that used to be int64 got converted to float64 during pivoting.\n",
    "\n",
    "    # Load the daily dataset.\n",
    "    # rename columns because provided column headers contain non-ascii characters\n",
    "    daily_columns = ['time', 'temperature_2m_degF_max','temperature_2m_degF_min', \n",
    "                     'rain_inch', 'snowfall_cm', 'precipitation_hours']\n",
    "    raw_daily_df1 = pd.read_csv(daily_input_file, skiprows=4, names=daily_columns)\n",
    "    # convert ISO date into datetime\n",
    "    raw_daily_df1[\"date\"] = raw_daily_df1['time'].map(lambda x: datetime.datetime.fromisoformat(x))\n",
    "    raw_daily_df1.drop('time', axis=1, inplace=True)\n",
    "\n",
    "    # join dataframes\n",
    "    # warning says, flatten column names or else join will throw errors in future versions\n",
    "    clean_hrly_df1.columns = clean_hrly_df1.columns.to_flat_index()\n",
    "    awesome_df = raw_daily_df1.join(clean_hrly_df1, on = 'date' )\n",
    "    \n",
    "    # Parse date into numbers: year, month, and day-of-the-year.\n",
    "    # The 'month' field is for the month-label machine learning. \n",
    "    # The day_of_year field is for the season-clusters machine learning. \n",
    "    # The 'year' field is for maybe pivoting on, for the season-clusters machine learning. \n",
    "    # The day_of_year field runs from 1 to 365 (366 for leap years): February 3rd would be 34. \n",
    "    # We keep the whole date formatted as datetime for time intervals like 2011-12-28 to 2012-01-17.\n",
    "    awesome_df['year'] = awesome_df[\"date\"].map(lambda x: x.year)\n",
    "    awesome_df['month'] = awesome_df[\"date\"].map(lambda x: x.month)\n",
    "    # the next tw lines of code are stolen from\n",
    "    # https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-11.php\n",
    "    # which says nothing about licenses\n",
    "    def day_of_year(x):\n",
    "        return (x - datetime.datetime(x.year, 1, 1)).days + 1\n",
    "    awesome_df['day_of_year'] = awesome_df[\"date\"].map(lambda x: day_of_year(x))\n",
    "    \n",
    "    # finally, write out the result\n",
    "    awesome_df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e0a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_step1('chi_hourly.csv', 'chi_daily.csv', 'chi_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70e5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637a085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca7c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b6701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
